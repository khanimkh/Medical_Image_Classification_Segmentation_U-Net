{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep Learning Framework (Model Training and Evaluation)**\n",
        "\n",
        "McMedHacks"
      ],
      "metadata": {
        "id": "JHEQIXSOwk8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is PyTorch?**\n",
        "\n",
        "PyTorch is an open-source Python library for deep learning developed and maintained by Facebook. The project started in 2016 and quickly became a popular framework among developers and researchers.\n",
        "\n",
        "**What is Torch?**\n",
        "\n",
        "Torch (Torch7) is an open-source project for deep learning written in C and generally used via the Lua interface. It was a precursor project to PyTorch and is no longer actively developed.\n",
        "\n",
        "**How to install pytorch?**\n",
        "\n",
        "[Official website](https://pytorch.org/)"
      ],
      "metadata": {
        "id": "MI19SRkaw3GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch"
      ],
      "metadata": {
        "id": "qPU2iQ3Ew2T4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364a607e-7732-4ada-e987-f83ad4da485b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch\n",
            "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
            "Building wheels for collected packages: pytorch\n",
            "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for pytorch\n",
            "Failed to build pytorch\n",
            "Installing collected packages: pytorch\n",
            "    Running setup.py install for pytorch ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-nv2you1t/pytorch_b036fe6c74084df7a29322bc65805f4c/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-nv2you1t/pytorch_b036fe6c74084df7a29322bc65805f4c/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-2cro9ly6/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/pytorch Check the logs for full command output.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if it is installed:"
      ],
      "metadata": {
        "id": "3fIIv7Ww1M4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "LWh-TdQu07zU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db928aa-11c4-48d8-9ef7-7895bcad8872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some important context in torch:**\n",
        "\n",
        "**Dataset** : [Documentation](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)"
      ],
      "metadata": {
        "id": "urK1B00R1cWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "from pandas import read_csv\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# dataset definition\n",
        "class CSVDataset(Dataset):\n",
        "    # load the dataset\n",
        "    def __init__(self, path):\n",
        "        # load the csv file as a dataframe\n",
        "        df = read_csv(path, header=None)\n",
        "        # store the inputs and outputs\n",
        "        self.X = df.values[:, :-1]\n",
        "        self.y = df.values[:, -1]\n",
        "        # self.X=(self.X-self.X.mean())/self.X.std()\n",
        "        # ensure input data is floats\n",
        "        self.X = self.X.astype('float32')\n",
        "        # label encode target and ensure the values are floats\n",
        "        # self.y = LabelEncoder().fit_transform(self.y)\n",
        "        self.y = self.y.astype('float32')-1\n",
        "        self.y = self.y.reshape((len(self.y), 1))\n",
        "\n",
        "    # number of rows in the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    # get a row at an index\n",
        "    def __getitem__(self, idx):\n",
        "        return [self.X[idx], self.y[idx]]\n",
        "\n",
        "    # get indexes for train and test rows\n",
        "    def get_splits(self, n_test=0.2):\n",
        "        # determine sizes\n",
        "        test_size = round(n_test * len(self.X))\n",
        "        train_size = len(self.X) - test_size\n",
        "        # calculate the split\n",
        "        return random_split(self, [train_size, test_size])"
      ],
      "metadata": {
        "id": "Z2fb3UXf1cG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------"
      ],
      "metadata": {
        "id": "QuOq3YWuUO32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DataLoader** : [Documentation](https://pytorch.org/docs/stable/data.html)"
      ],
      "metadata": {
        "id": "WzbCaFEGLVDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# prepare the dataset\n",
        "def prepare_data(path):\n",
        "    # load the dataset\n",
        "    dataset = CSVDataset(path)\n",
        "    # calculate split\n",
        "    train, test = dataset.get_splits()\n",
        "    # prepare data loaders\n",
        "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
        "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
        "    return train_dl, test_dl"
      ],
      "metadata": {
        "id": "D5xaCZ2HDGOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------"
      ],
      "metadata": {
        "id": "rinWvh6lUQ6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model** : [Documentation](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)"
      ],
      "metadata": {
        "id": "nEb0KEm7TnH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Linear\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import Sigmoid\n",
        "from torch.nn import Module\n",
        "from torch.nn.init import kaiming_uniform_\n",
        "from torch.nn.init import xavier_uniform_\n",
        "\n",
        "# model definition\n",
        "class MLP(Module):\n",
        "    # define model elements\n",
        "    def __init__(self, n_inputs):\n",
        "        super(MLP, self).__init__()\n",
        "        # input to first hidden layer\n",
        "        self.hidden1 = Linear(n_inputs, 10)\n",
        "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
        "        self.act1 = ReLU()\n",
        "        # second hidden layer\n",
        "        self.hidden2 = Linear(10, 8)\n",
        "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
        "        self.act2 = ReLU()\n",
        "        # third hidden layer and output\n",
        "        self.hidden3 = Linear(8, 1)\n",
        "        xavier_uniform_(self.hidden3.weight)\n",
        "        self.act3 = Sigmoid()\n",
        "\n",
        "    # forward propagate input\n",
        "    def forward(self, X):\n",
        "        # input to first hidden layer\n",
        "        X = self.hidden1(X)\n",
        "        X = self.act1(X)\n",
        "         # second hidden layer\n",
        "        X = self.hidden2(X)\n",
        "        X = self.act2(X)\n",
        "        # third hidden layer and output\n",
        "        X = self.hidden3(X)\n",
        "        X = self.act3(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "N8ET67a3C16K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "FxLZGYxDUTLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizer and loss : [Documentation](https://pytorch.org/docs/stable/optim.html)"
      ],
      "metadata": {
        "id": "vwR7QaYRUU7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD\n",
        "from torch.nn import BCELoss\n",
        "\n",
        "# train the model\n",
        "def train_model(train_dl, model):\n",
        "    # define the optimization\n",
        "    criterion = BCELoss()\n",
        "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    # enumerate epochs\n",
        "    for epoch in range(100):\n",
        "        # enumerate mini batches\n",
        "        for i, (inputs, targets) in enumerate(train_dl):\n",
        "            # clear the gradients\n",
        "            optimizer.zero_grad()\n",
        "            # compute the model output\n",
        "            yhat = model(inputs)\n",
        "            # calculate loss\n",
        "            loss = criterion(yhat, targets)\n",
        "            # credit assignment\n",
        "            loss.backward()\n",
        "            # update model weights\n",
        "            optimizer.step()"
      ],
      "metadata": {
        "id": "SyeSkPuGUUwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import vstack\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch import Tensor\n",
        "\n",
        "# make a class prediction for one row of data\n",
        "def predict(row, model):\n",
        "    # convert row to data\n",
        "    row = Tensor([row])\n",
        "    # make prediction\n",
        "    yhat = model(row)\n",
        "    # retrieve numpy array\n",
        "    yhat = yhat.detach().numpy()\n",
        "    return yhat\n",
        "\n",
        "# evaluate the model\n",
        "def evaluate_model(test_dl, model):\n",
        "    predictions, actuals = list(), list()\n",
        "    for i, (inputs, targets) in enumerate(test_dl):\n",
        "        # evaluate the model on the test set\n",
        "        yhat = model(inputs)\n",
        "        # retrieve numpy array\n",
        "        yhat = yhat.detach().numpy()\n",
        "        actual = targets.numpy()\n",
        "        actual = actual.reshape((len(actual), 1))\n",
        "        # round to class values\n",
        "        yhat = yhat.round()\n",
        "        # store\n",
        "        predictions.append(yhat)\n",
        "        actuals.append(actual)\n",
        "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
        "    # calculate accuracy\n",
        "    acc = accuracy_score(actuals, predictions)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "ZXtYBQjSmFWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main pipeline"
      ],
      "metadata": {
        "id": "Ntyg09-GnDE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the data\n",
        "# https://archive.ics.uci.edu/ml/datasets/Liver+Disorders\n",
        "path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/liver-disorders/bupa.data'\n",
        "train_dl, test_dl = prepare_data(path)\n",
        "print(len(train_dl.dataset), len(test_dl.dataset))\n",
        "# define the network\n",
        "model = MLP(6)\n",
        "# train the model\n",
        "train_model(train_dl, model)\n",
        "# evaluate the model\n",
        "acc = evaluate_model(test_dl, model)\n",
        "print('Accuracy: %.3f' % acc)\n",
        "# make a single prediction (expect class=1)\n",
        "row = [88,67,21,11,11,0.5]\n",
        "yhat = predict(row, model)\n",
        "print('Predicted: %.3f (class=%d)' % (yhat, yhat.round()))"
      ],
      "metadata": {
        "id": "d4poo-hemYXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49df3397-ba9c-493e-a90d-4aa6d36f7e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "276 69\n",
            "Accuracy: 0.536\n",
            "Predicted: 1.000 (class=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How we can improve it?**"
      ],
      "metadata": {
        "id": "r81E3jWVQih1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Normalization\n",
        "*   Feature Engineering\n",
        "*   Learning rate\n",
        "*   Epoch\n",
        "*   Loss\n",
        "  * KL\n",
        "  * Weighted loss\n",
        "*   Optimizer\n",
        "  * Adam\n",
        "  * AdamW\n",
        "*   Regularization\n",
        "  * optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ex0CieixQmVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "urnOKSedRStF"
      }
    }
  ]
}